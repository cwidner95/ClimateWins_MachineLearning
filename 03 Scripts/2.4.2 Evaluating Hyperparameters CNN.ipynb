{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add67743-4fe2-4f44-bfb9-29547a387f7f",
   "metadata": {},
   "source": [
    "# 2.4.2 Evaluating Hyperparameters RNN\n",
    "## This script contain the following points:\n",
    "### 01. Importing Libraries and Data\n",
    "### 02. Optimizing Hyperparameters\n",
    "### 03. Running CNN Model with Optimized Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ca28b-d934-4dbc-b27c-eaa7f34ced38",
   "metadata": {},
   "source": [
    "### 01. Importing Libraria and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7581fe6d-3f80-478d-8059-5a30c84937be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier  # Use scikeras for scikit-learn compatibility\n",
    "from math import floor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow.keras.layers import LeakyReLU  # Use tensorflow.keras instead of keras\n",
    "LeakyReLU = LeakyReLU(negative_slope=0.1)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c34f75-5dbd-4e51-96b6-cfac61213f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating path variable\n",
    "path = r'/home/cwidner/Documents/CareerFoundry/MachineLearning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399938f0-3863-45e6-9bf5-fbdfe44bf3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 136)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in cleaned weather dataset\n",
    "df_weather = pd.read_csv(os.path.join(path,'02 Data','Prepared Data','weather_cleaned.csv'),index_col=False)\n",
    "df_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f817e08f-83c8-448c-b936-1ae6548ae0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_cloud_cover</th>\n",
       "      <th>BASEL_humidity</th>\n",
       "      <th>BASEL_pressure</th>\n",
       "      <th>BASEL_global_radiation</th>\n",
       "      <th>BASEL_precipitation</th>\n",
       "      <th>BASEL_sunshine</th>\n",
       "      <th>BASEL_temp_mean</th>\n",
       "      <th>BASEL_temp_min</th>\n",
       "      <th>BASEL_temp_max</th>\n",
       "      <th>BELGRADE_cloud_cover</th>\n",
       "      <th>...</th>\n",
       "      <th>STOCKHOLM_temp_max</th>\n",
       "      <th>VALENTIA_cloud_cover</th>\n",
       "      <th>VALENTIA_humidity</th>\n",
       "      <th>VALENTIA_pressure</th>\n",
       "      <th>VALENTIA_global_radiation</th>\n",
       "      <th>VALENTIA_precipitation</th>\n",
       "      <th>VALENTIA_sunshine</th>\n",
       "      <th>VALENTIA_temp_mean</th>\n",
       "      <th>VALENTIA_temp_min</th>\n",
       "      <th>VALENTIA_temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0328</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  BASEL_global_radiation  \\\n",
       "0                  7            0.85           1.018                    0.32   \n",
       "1                  6            0.84           1.018                    0.36   \n",
       "2                  8            0.90           1.018                    0.18   \n",
       "3                  3            0.92           1.018                    0.58   \n",
       "4                  6            0.95           1.018                    0.65   \n",
       "\n",
       "   BASEL_precipitation  BASEL_sunshine  BASEL_temp_mean  BASEL_temp_min  \\\n",
       "0                 0.09             0.7              6.5             0.8   \n",
       "1                 1.05             1.1              6.1             3.3   \n",
       "2                 0.30             0.0              8.5             5.1   \n",
       "3                 0.00             4.1              6.3             3.8   \n",
       "4                 0.14             5.4              3.0            -0.7   \n",
       "\n",
       "   BASEL_temp_max  BELGRADE_cloud_cover  ...  STOCKHOLM_temp_max  \\\n",
       "0            10.9                     1  ...                 4.9   \n",
       "1            10.1                     6  ...                 5.0   \n",
       "2             9.9                     6  ...                 4.1   \n",
       "3            10.6                     8  ...                 2.3   \n",
       "4             6.0                     8  ...                 4.3   \n",
       "\n",
       "   VALENTIA_cloud_cover  VALENTIA_humidity  VALENTIA_pressure  \\\n",
       "0                     5               0.88             1.0003   \n",
       "1                     7               0.91             1.0007   \n",
       "2                     7               0.91             1.0096   \n",
       "3                     7               0.86             1.0184   \n",
       "4                     3               0.80             1.0328   \n",
       "\n",
       "   VALENTIA_global_radiation  VALENTIA_precipitation  VALENTIA_sunshine  \\\n",
       "0                       0.45                    0.34                4.7   \n",
       "1                       0.25                    0.84                0.7   \n",
       "2                       0.17                    0.08                0.1   \n",
       "3                       0.13                    0.98                0.0   \n",
       "4                       0.46                    0.00                5.7   \n",
       "\n",
       "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
       "0                 8.5                6.0               10.9  \n",
       "1                 8.9                5.6               12.1  \n",
       "2                10.5                8.1               12.9  \n",
       "3                 7.4                7.3               10.6  \n",
       "4                 5.7                3.0                8.4  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff8757c-34d1-45da-bdd2-031dcd66265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in cleaned pleasant dataset\n",
    "df_pleasant = pd.read_csv(os.path.join(path,'02 Data','Prepared Data','pleasant_weather_cleaned.csv'),index_col=False)\n",
    "df_pleasant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55304c5-c85d-4cd1-9f94-f93373ff5ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_pleasant_weather</th>\n",
       "      <th>BELGRADE_pleasant_weather</th>\n",
       "      <th>BUDAPEST_pleasant_weather</th>\n",
       "      <th>DEBILT_pleasant_weather</th>\n",
       "      <th>DUSSELDORF_pleasant_weather</th>\n",
       "      <th>HEATHROW_pleasant_weather</th>\n",
       "      <th>KASSEL_pleasant_weather</th>\n",
       "      <th>LJUBLJANA_pleasant_weather</th>\n",
       "      <th>MAASTRICHT_pleasant_weather</th>\n",
       "      <th>MADRID_pleasant_weather</th>\n",
       "      <th>MUNCHENB_pleasant_weather</th>\n",
       "      <th>OSLO_pleasant_weather</th>\n",
       "      <th>SONNBLICK_pleasant_weather</th>\n",
       "      <th>STOCKHOLM_pleasant_weather</th>\n",
       "      <th>VALENTIA_pleasant_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
       "0                       0                          0   \n",
       "1                       0                          0   \n",
       "2                       0                          0   \n",
       "3                       0                          0   \n",
       "4                       0                          0   \n",
       "\n",
       "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            0                        0   \n",
       "3                            0                        0   \n",
       "4                            0                        0   \n",
       "\n",
       "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   VALENTIA_pleasant_weather  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pleasant.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df_pleasant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3987e-5ed8-4718-bcc4-851bc3d11ea1",
   "metadata": {},
   "source": [
    "### 02 Optimizing Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef2b1892-c24a-4b40-9b69-d681668c390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 135)\n",
      "(22950, 15)\n"
     ]
    }
   ],
   "source": [
    "# Create matrices\n",
    "X = df_weather\n",
    "y = df_pleasant\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e98615-5247-4edb-a8e9-4834f027ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 135)\n"
     ]
    }
   ],
   "source": [
    "# Create matrices\n",
    "X = X.to_numpy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8a5613-01fc-43d4-bfff-7563ecc037da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22950, 15, 9)\n"
     ]
    }
   ],
   "source": [
    "# Reshape X to (22950, 15, 9)\n",
    "\n",
    "X = X.reshape(-1, 15, 9)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d10f772-bc8f-45ac-ba1e-decf563aee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef57a62-b066-47c5-87ac-5b3b7d3d2732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape after argmax: (22950,)\n"
     ]
    }
   ],
   "source": [
    "# Reshape y to (22950,)\n",
    "y = np.argmax(y, axis=1)\n",
    "print(\"y shape after argmax:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb2f2ab-f2f8-4b69-8a51-3835d92395b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in yto ensure it's correct\n",
    "print(\"Unique values in y:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88c2a9f3-38d8-4fde-85ba-3375311ae5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a76b4f18-165b-4a11-bc5a-47f47814f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea46dccc-c162-4b52-be7f-ea49672c2f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53b141e-ad48-4c39-abe5-dfc8910a8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of time steps for the input data\n",
    "timesteps = X_train.shape[1]\n",
    "\n",
    "# Determine the dimensionality of the input data\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "# Specify the number of classes for the target variable\n",
    "n_classes = 15  \n",
    "\n",
    "# Create a scorer for accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a57d936f-7786-413a-b065-1c9d40ea567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl', 'SGD']\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU, 'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer_name = optimizerL[round(optimizer)]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "\n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, input_dim)))\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel, activation=activation))\n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=127))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax'))  # sigmoid softmax\n",
    "        \n",
    "        # Create a new optimizer instance for each iteration\n",
    "        if optimizer_name == 'Adam':\n",
    "            optimizer_instance = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'SGD':\n",
    "            optimizer_instance = SGD(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'RMSprop':\n",
    "            optimizer_instance = RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adadelta':\n",
    "            optimizer_instance = Adadelta(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adagrad':\n",
    "            optimizer_instance = Adagrad(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Adamax':\n",
    "            optimizer_instance = Adamax(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Nadam':\n",
    "            optimizer_instance = Nadam(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'Ftrl':\n",
    "            optimizer_instance = Ftrl(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer_instance, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=20)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=127)\n",
    "    results = []\n",
    "    for train, test in kfold.split(X, y):\n",
    "        model = cnn_model()\n",
    "        model.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=0, callbacks=[es])\n",
    "        scores = model.evaluate(X[test], y[test], verbose=1)\n",
    "        results.append(scores[1])  # Assuming accuracy is the second metric\n",
    "    return np.mean(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3fe1b20-068f-41a1-9d86-95a83307c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 27: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 147.1270\n",
      "Epoch 25: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 39.1203\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 44.6849\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 55.7117\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0306 - loss: 96.9454  \n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5218   \u001b[39m | \u001b[39m4.714    \u001b[39m | \u001b[39m232.0    \u001b[39m | \u001b[39m0.186    \u001b[39m | \u001b[39m0.4546   \u001b[39m | \u001b[39m64.17    \u001b[39m | \u001b[39m1.173    \u001b[39m | \u001b[39m1.883    \u001b[39m | \u001b[39m2.431    \u001b[39m | \u001b[39m0.6709   \u001b[39m | \u001b[39m52.56    \u001b[39m | \u001b[39m0.9062   \u001b[39m | \u001b[39m0.7344   \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.1405\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: nan\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.6434   \u001b[39m | \u001b[35m1.573    \u001b[39m | \u001b[35m271.1    \u001b[39m | \u001b[35m0.6497   \u001b[39m | \u001b[35m0.3143   \u001b[39m | \u001b[35m56.8     \u001b[39m | \u001b[35m2.813    \u001b[39m | \u001b[35m1.188    \u001b[39m | \u001b[35m2.266    \u001b[39m | \u001b[35m0.2669   \u001b[39m | \u001b[35m92.48    \u001b[39m | \u001b[35m0.1275   \u001b[39m | \u001b[35m0.4802   \u001b[39m |\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 2.6138\n",
      "Epoch 27: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: 3.1342\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 1.9873\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: 10.3864\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: 42.5351\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m6.052    \u001b[39m | \u001b[39m361.9    \u001b[39m | \u001b[39m0.4819   \u001b[39m | \u001b[39m0.3475   \u001b[39m | \u001b[39m83.42    \u001b[39m | \u001b[39m1.691    \u001b[39m | \u001b[39m2.908    \u001b[39m | \u001b[39m2.201    \u001b[39m | \u001b[39m0.3927   \u001b[39m | \u001b[39m67.47    \u001b[39m | \u001b[39m0.8815   \u001b[39m | \u001b[39m1.416    \u001b[39m |\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.1905\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 4.8854\n",
      "Epoch 25: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 2.3606\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6614 - loss: 2.9964\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.2841\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m5.379    \u001b[39m | \u001b[39m539.7    \u001b[39m | \u001b[39m0.201    \u001b[39m | \u001b[39m0.3324   \u001b[39m | \u001b[39m58.97    \u001b[39m | \u001b[39m1.07     \u001b[39m | \u001b[39m1.821    \u001b[39m | \u001b[39m2.718    \u001b[39m | \u001b[39m0.3971   \u001b[39m | \u001b[39m31.79    \u001b[39m | \u001b[39m0.9366   \u001b[39m | \u001b[39m5.283    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.1474\n",
      "Epoch 28: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 1.1474\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 1.1623\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 1.1797\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.1614\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m8.951    \u001b[39m | \u001b[39m292.0    \u001b[39m | \u001b[39m0.1595   \u001b[39m | \u001b[39m0.4401   \u001b[39m | \u001b[39m61.92    \u001b[39m | \u001b[39m1.349    \u001b[39m | \u001b[39m1.874    \u001b[39m | \u001b[39m2.395    \u001b[39m | \u001b[39m0.5142   \u001b[39m | \u001b[39m74.0     \u001b[39m | \u001b[39m0.2923   \u001b[39m | \u001b[39m2.465    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7975 - loss: 0.6312\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.7718\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7000 - loss: 0.9025\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7740 - loss: 0.6936\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.4681\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.7692   \u001b[39m | \u001b[35m2.783    \u001b[39m | \u001b[35m778.9    \u001b[39m | \u001b[35m0.1646   \u001b[39m | \u001b[35m0.3458   \u001b[39m | \u001b[35m31.58    \u001b[39m | \u001b[35m1.392    \u001b[39m | \u001b[35m2.01     \u001b[39m | \u001b[35m1.545    \u001b[39m | \u001b[35m0.2438   \u001b[39m | \u001b[35m41.07    \u001b[39m | \u001b[35m0.9895   \u001b[39m | \u001b[35m4.893    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.8408 - loss: 0.4349\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7414 - loss: 0.7123\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7621 - loss: 0.6879\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7359 - loss: 0.7259\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7868 - loss: 0.6441\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7635   \u001b[39m | \u001b[39m4.522    \u001b[39m | \u001b[39m744.1    \u001b[39m | \u001b[39m0.9174   \u001b[39m | \u001b[39m0.4632   \u001b[39m | \u001b[39m96.58    \u001b[39m | \u001b[39m2.627    \u001b[39m | \u001b[39m1.598    \u001b[39m | \u001b[39m1.644    \u001b[39m | \u001b[39m0.677    \u001b[39m | \u001b[39m14.0     \u001b[39m | \u001b[39m0.7135   \u001b[39m | \u001b[39m3.301    \u001b[39m |\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0017 - loss: 728.5831\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: 274.8061\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 131.2654\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3133 - loss: 155051376.0000\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 735.7123\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.4425   \u001b[39m | \u001b[39m5.759    \u001b[39m | \u001b[39m605.0    \u001b[39m | \u001b[39m0.1657   \u001b[39m | \u001b[39m0.3829   \u001b[39m | \u001b[39m90.37    \u001b[39m | \u001b[39m2.722    \u001b[39m | \u001b[39m1.829    \u001b[39m | \u001b[39m2.336    \u001b[39m | \u001b[39m0.757    \u001b[39m | \u001b[39m82.59    \u001b[39m | \u001b[39m0.674    \u001b[39m | \u001b[39m2.146    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.1381\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: nan\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: 1.1238\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: 1.1298\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m1.71     \u001b[39m | \u001b[39m383.0    \u001b[39m | \u001b[39m0.1859   \u001b[39m | \u001b[39m0.3541   \u001b[39m | \u001b[39m79.76    \u001b[39m | \u001b[39m1.194    \u001b[39m | \u001b[39m1.526    \u001b[39m | \u001b[39m2.075    \u001b[39m | \u001b[39m0.9041   \u001b[39m | \u001b[39m84.38    \u001b[39m | \u001b[39m0.8003   \u001b[39m | \u001b[39m0.09905  \u001b[39m |\n",
      "Epoch 28: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.4806\n",
      "Epoch 30: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1860 - loss: 1.3668\n",
      "Epoch 37: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 1.1745  \n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6617 - loss: 1.2829\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.4252\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.5534   \u001b[39m | \u001b[39m8.678    \u001b[39m | \u001b[39m869.4    \u001b[39m | \u001b[39m0.6053   \u001b[39m | \u001b[39m0.3531   \u001b[39m | \u001b[39m71.57    \u001b[39m | \u001b[39m2.462    \u001b[39m | \u001b[39m1.09     \u001b[39m | \u001b[39m2.968    \u001b[39m | \u001b[39m0.9803   \u001b[39m | \u001b[39m46.71    \u001b[39m | \u001b[39m0.6235   \u001b[39m | \u001b[39m2.347    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.1380\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 1.1485\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 1.1414\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 1.1482\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.1510\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m1.267    \u001b[39m | \u001b[39m961.5    \u001b[39m | \u001b[39m0.8919   \u001b[39m | \u001b[39m0.4301   \u001b[39m | \u001b[39m81.52    \u001b[39m | \u001b[39m2.994    \u001b[39m | \u001b[39m2.373    \u001b[39m | \u001b[39m1.792    \u001b[39m | \u001b[39m0.05079  \u001b[39m | \u001b[39m45.2     \u001b[39m | \u001b[39m0.7669   \u001b[39m | \u001b[39m6.906    \u001b[39m |\n",
      "Epoch 37: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6495 - loss: 9518518.0000\n",
      "Epoch 53: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5834 - loss: 763354.1875\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5769 - loss: 4353877.0000  \n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6506 - loss: 39214304.0000\n",
      "Epoch 37: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.4019 - loss: 9123374.0000\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.56     \u001b[39m | \u001b[39m7.83     \u001b[39m | \u001b[39m284.2    \u001b[39m | \u001b[39m0.2654   \u001b[39m | \u001b[39m0.4736   \u001b[39m | \u001b[39m97.1     \u001b[39m | \u001b[39m1.922    \u001b[39m | \u001b[39m1.464    \u001b[39m | \u001b[39m2.467    \u001b[39m | \u001b[39m0.9535   \u001b[39m | \u001b[39m44.37    \u001b[39m | \u001b[39m0.1684   \u001b[39m | \u001b[39m1.164    \u001b[39m |\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 22.5866\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 22.9203 \n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6520 - loss: 14.4329\n",
      "Epoch 54: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 2468.6597 \n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0757 - loss: 8.8081  \n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.5296   \u001b[39m | \u001b[39m5.513    \u001b[39m | \u001b[39m996.0    \u001b[39m | \u001b[39m0.9747   \u001b[39m | \u001b[39m0.3528   \u001b[39m | \u001b[39m96.45    \u001b[39m | \u001b[39m1.56     \u001b[39m | \u001b[39m1.62     \u001b[39m | \u001b[39m2.64     \u001b[39m | \u001b[39m0.9727   \u001b[39m | \u001b[39m19.0     \u001b[39m | \u001b[39m0.7042   \u001b[39m | \u001b[39m5.893    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.1407\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: 1.1436\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 1.1444\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: 1.1282\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: 1.1344\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.6434   \u001b[39m | \u001b[39m2.229    \u001b[39m | \u001b[39m222.4    \u001b[39m | \u001b[39m0.215    \u001b[39m | \u001b[39m0.4863   \u001b[39m | \u001b[39m95.6     \u001b[39m | \u001b[39m2.074    \u001b[39m | \u001b[39m1.007    \u001b[39m | \u001b[39m2.594    \u001b[39m | \u001b[39m0.2169   \u001b[39m | \u001b[39m85.73    \u001b[39m | \u001b[39m0.3766   \u001b[39m | \u001b[39m1.242    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7859 - loss: 0.5963\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.5798\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.6307\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.7399\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.5593\n",
      "| \u001b[35m15       \u001b[39m | \u001b[35m0.7745   \u001b[39m | \u001b[35m3.8      \u001b[39m | \u001b[35m283.3    \u001b[39m | \u001b[35m0.7075   \u001b[39m | \u001b[35m0.4555   \u001b[39m | \u001b[35m34.66    \u001b[39m | \u001b[35m1.933    \u001b[39m | \u001b[35m2.556    \u001b[39m | \u001b[35m2.461    \u001b[39m | \u001b[35m0.05664  \u001b[39m | \u001b[35m78.55    \u001b[39m | \u001b[35m0.4846   \u001b[39m | \u001b[35m0.4789   \u001b[39m |\n",
      "Epoch 26: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.4718 - loss: 1.9779\n",
      "Epoch 54: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.4840 - loss: 2.5097\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.3089 - loss: 5.1675\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.5939 - loss: 1.2923\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.5092 - loss: 2.9236\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.4488   \u001b[39m | \u001b[39m2.908    \u001b[39m | \u001b[39m745.3    \u001b[39m | \u001b[39m0.8325   \u001b[39m | \u001b[39m0.3911   \u001b[39m | \u001b[39m97.89    \u001b[39m | \u001b[39m1.516    \u001b[39m | \u001b[39m1.428    \u001b[39m | \u001b[39m2.272    \u001b[39m | \u001b[39m0.8992   \u001b[39m | \u001b[39m14.38    \u001b[39m | \u001b[39m0.3916   \u001b[39m | \u001b[39m5.408    \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8092 - loss: 0.5519\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.8151 - loss: 0.5431\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.8189 - loss: 0.5123\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8163 - loss: 0.5234\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8518 - loss: 0.4151\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m0.8192   \u001b[39m | \u001b[35m3.238    \u001b[39m | \u001b[35m858.1    \u001b[39m | \u001b[35m0.4023   \u001b[39m | \u001b[35m0.3935   \u001b[39m | \u001b[35m60.45    \u001b[39m | \u001b[35m2.112    \u001b[39m | \u001b[35m2.117    \u001b[39m | \u001b[35m2.337    \u001b[39m | \u001b[35m0.06153  \u001b[39m | \u001b[35m12.58    \u001b[39m | \u001b[35m0.4579   \u001b[39m | \u001b[35m0.9024   \u001b[39m |\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6951 - loss: 2.9433\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 3.4216\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5558 - loss: 4.2164\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6468 - loss: 5.3011\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6461 - loss: 5.8852\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.6421   \u001b[39m | \u001b[39m2.745    \u001b[39m | \u001b[39m462.7    \u001b[39m | \u001b[39m0.2858   \u001b[39m | \u001b[39m0.3528   \u001b[39m | \u001b[39m30.56    \u001b[39m | \u001b[39m1.299    \u001b[39m | \u001b[39m1.366    \u001b[39m | \u001b[39m1.135    \u001b[39m | \u001b[39m0.1095   \u001b[39m | \u001b[39m97.15    \u001b[39m | \u001b[39m0.8575   \u001b[39m | \u001b[39m6.061    \u001b[39m |\n",
      "Epoch 22: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6451 - loss: 1.1379\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.6318\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6520 - loss: 1.1405\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7098 - loss: 0.7943\n",
      "Epoch 20: early stopping\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 1.1355\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.6768   \u001b[39m | \u001b[39m7.598    \u001b[39m | \u001b[39m377.8    \u001b[39m | \u001b[39m0.4762   \u001b[39m | \u001b[39m0.4064   \u001b[39m | \u001b[39m50.59    \u001b[39m | \u001b[39m2.725    \u001b[39m | \u001b[39m1.614    \u001b[39m | \u001b[39m1.574    \u001b[39m | \u001b[39m0.1622   \u001b[39m | \u001b[39m60.6     \u001b[39m | \u001b[39m0.5093   \u001b[39m | \u001b[39m6.768    \u001b[39m |\n",
      "=========================================================================================================================================================================\n",
      "Search took 15.825993744532267 minutes\n"
     ]
    }
   ],
   "source": [
    "# Start timing the Bayesian Optimization process\n",
    "start = time.time()\n",
    "\n",
    "# Define the hyperparameter space for Bayesian Optimization\n",
    "params = {\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation': (0, 9),  # 9\n",
    "    'optimizer': (0, 7),  # 7\n",
    "    'learning_rate': (0.001, 1),\n",
    "    'batch_size': (200, 1000), #(10, 50), #\n",
    "    'epochs': (20, 100),\n",
    "    'layers1': (1, 3),\n",
    "    'layers2': (1, 3),\n",
    "    'normalization': (0, 1),\n",
    "    'dropout': (0, 1),\n",
    "    'dropout_rate': (0.3, 0.5)\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=127)\n",
    "nn_opt.maximize(init_points=15, n_iter=4)  # 25\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50c78127-591b-4aa4-a028-1ebeee9bf054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 3.238346333286747, 'batch_size': 858.0863899431488, 'dropout': 0.40228837505867143, 'dropout_rate': 0.393459528897498, 'epochs': 60.44669476125228, 'kernel': 2.1120927218648693, 'layers1': 2.1169196169026234, 'layers2': 2.3365351568358195, 'learning_rate': 0.06152500093002812, 'neurons': 12.581466622198223, 'normalization': 0.45787219367534804, 'optimizer': 0.902427852988836}\n",
      "Highest Accuracy: 0.8191721081733704\n"
     ]
    }
   ],
   "source": [
    "best_params = nn_opt.max['params']\n",
    "best_score = nn_opt.max['target']\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Highest Accuracy: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93a7c28-d6d7-433c-86df-5c8e3b0271d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "Activation: softsign\n",
      "Batch Size: 858\n",
      "Dropout Rate: 0.3935\n",
      "Epochs: 60\n",
      "Kernel Size: 2\n",
      "Layers1: 2\n",
      "Layers2: 2\n",
      "Learning Rate: 0.0615\n",
      "Neurons: 13\n",
      "Normalization: 0.4579\n",
      "Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best parameters from the optimization result\n",
    "optimum = nn_opt.max['params']\n",
    "\n",
    "# Assign the best parameters to their respective variables\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'LeakyReLU', 'relu']\n",
    "activation = activationL[round(optimum['activation'])]\n",
    "\n",
    "# Convert the hyperparameters to their integer form where necessary\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimum['kernel'] = round(optimum['kernel'])\n",
    "\n",
    "optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "optimizerD = {\n",
    "    'SGD': SGD(learning_rate=learning_rate),\n",
    "    'Adam': Adam(learning_rate=learning_rate),\n",
    "    'RMSprop': RMSprop(learning_rate=learning_rate),\n",
    "    'Adadelta': Adadelta(learning_rate=learning_rate),\n",
    "    'Adagrad': Adagrad(learning_rate=learning_rate),\n",
    "    'Adamax': Adamax(learning_rate=learning_rate),\n",
    "    'Nadam': Nadam(learning_rate=learning_rate),\n",
    "    'Ftrl': Ftrl(learning_rate=learning_rate)\n",
    "}\n",
    "\n",
    "# Retrieve the optimizer name\n",
    "optimizer_name = optimizerL[round(optimum['optimizer'])]\n",
    "\n",
    "# Print the optimum parameters in a readable format\n",
    "print(f\"Best Parameters: \")\n",
    "print(f\"Activation: {activation}\")\n",
    "print(f\"Batch Size: {optimum['batch_size']}\")\n",
    "print(f\"Dropout Rate: {optimum['dropout_rate']:.4f}\")\n",
    "print(f\"Epochs: {optimum['epochs']}\")\n",
    "print(f\"Kernel Size: {optimum['kernel']}\")\n",
    "print(f\"Layers1: {optimum['layers1']}\")\n",
    "print(f\"Layers2: {optimum['layers2']}\")\n",
    "print(f\"Learning Rate: {optimum['learning_rate']:.4f}\")\n",
    "print(f\"Neurons: {optimum['neurons']}\")\n",
    "print(f\"Normalization: {optimum['normalization']:.4f}\")\n",
    "print(f\"Optimizer: {optimizer_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebc612-8412-4201-9f6a-0b95bfa8388a",
   "metadata": {},
   "source": [
    "### 03. Running CNN Model with Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ade0f04d-6636-4699-9a5a-ecdabaf66dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwidner/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 1s - 40ms/step - accuracy: 0.6045 - loss: 1.2757\n",
      "Epoch 2/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6394 - loss: 1.0503\n",
      "Epoch 3/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6550 - loss: 0.9599\n",
      "Epoch 4/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6692 - loss: 0.9179\n",
      "Epoch 5/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6868 - loss: 0.8643\n",
      "Epoch 6/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6995 - loss: 0.8259\n",
      "Epoch 7/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7121 - loss: 0.8089\n",
      "Epoch 8/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7364 - loss: 0.7434\n",
      "Epoch 9/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7350 - loss: 0.7318\n",
      "Epoch 10/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7510 - loss: 0.6970\n",
      "Epoch 11/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7508 - loss: 0.7247\n",
      "Epoch 12/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7655 - loss: 0.6681\n",
      "Epoch 13/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7628 - loss: 0.6837\n",
      "Epoch 14/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7838 - loss: 0.6129\n",
      "Epoch 15/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7613 - loss: 0.6800\n",
      "Epoch 16/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7808 - loss: 0.6226\n",
      "Epoch 17/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7779 - loss: 0.5940\n",
      "Epoch 18/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7697 - loss: 0.6413\n",
      "Epoch 19/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7963 - loss: 0.5542\n",
      "Epoch 20/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8098 - loss: 0.5305\n",
      "Epoch 21/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7834 - loss: 0.6106\n",
      "Epoch 22/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7749 - loss: 0.6288\n",
      "Epoch 23/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7973 - loss: 0.5671\n",
      "Epoch 24/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8130 - loss: 0.5224\n",
      "Epoch 25/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8175 - loss: 0.5056\n",
      "Epoch 26/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8274 - loss: 0.4881\n",
      "Epoch 27/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7946 - loss: 0.5726\n",
      "Epoch 28/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8080 - loss: 0.5365\n",
      "Epoch 29/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7931 - loss: 0.5668\n",
      "Epoch 30/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7885 - loss: 0.5949\n",
      "Epoch 31/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8096 - loss: 0.5394\n",
      "Epoch 32/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8200 - loss: 0.5090\n",
      "Epoch 33/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8306 - loss: 0.4631\n",
      "Epoch 34/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8118 - loss: 0.5192\n",
      "Epoch 35/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8257 - loss: 0.4986\n",
      "Epoch 36/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8186 - loss: 0.5051\n",
      "Epoch 37/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8313 - loss: 0.4710\n",
      "Epoch 38/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8385 - loss: 0.4487\n",
      "Epoch 39/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8385 - loss: 0.4628\n",
      "Epoch 40/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8212 - loss: 0.4988\n",
      "Epoch 41/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8435 - loss: 0.4435\n",
      "Epoch 42/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8360 - loss: 0.4590\n",
      "Epoch 43/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7599 - loss: 0.6366\n",
      "Epoch 44/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7779 - loss: 0.5763\n",
      "Epoch 45/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7690 - loss: 0.6283\n",
      "Epoch 46/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7733 - loss: 0.6027\n",
      "Epoch 47/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7893 - loss: 0.5723\n",
      "Epoch 48/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7499 - loss: 0.6828\n",
      "Epoch 49/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7700 - loss: 0.6178\n",
      "Epoch 50/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.6813 - loss: 0.8642\n",
      "Epoch 51/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7357 - loss: 0.7169\n",
      "Epoch 52/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7583 - loss: 0.6360\n",
      "Epoch 53/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.7942 - loss: 0.5532\n",
      "Epoch 54/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8034 - loss: 0.5306\n",
      "Epoch 55/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8149 - loss: 0.4988\n",
      "Epoch 56/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8232 - loss: 0.4754\n",
      "Epoch 57/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8262 - loss: 0.4742\n",
      "Epoch 58/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8222 - loss: 0.4780\n",
      "Epoch 59/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8370 - loss: 0.4392\n",
      "Epoch 60/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8316 - loss: 0.4535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x75a3fb918d10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters from optimization\n",
    "best_params = {\n",
    "    'neurons': 13,\n",
    "    'kernel': 2,\n",
    "    'activation': 'softsign',\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.0615,\n",
    "    'batch_size': 858,\n",
    "    'epochs':60,\n",
    "    'layers1': 2,\n",
    "    'layers2': 2,\n",
    "    'normalization': 0.4579,\n",
    "    'dropout': 0.40228837505867143,\n",
    "    'dropout_rate':  0.3935\n",
    "}\n",
    "\n",
    "# Initialize optimizer with learning rate\n",
    "optimizers = {\n",
    "    'Adam': Adam(learning_rate=best_params['learning_rate']),\n",
    "    'SGD': SGD(learning_rate=best_params['learning_rate']),\n",
    "    'RMSprop': RMSprop(learning_rate=best_params['learning_rate']),\n",
    "    'Adadelta': Adadelta(learning_rate=best_params['learning_rate']),\n",
    "    'Adagrad': Adagrad(learning_rate=best_params['learning_rate']),\n",
    "    'Adamax': Adamax(learning_rate=best_params['learning_rate']),\n",
    "    'Nadam': Nadam(learning_rate=best_params['learning_rate']),\n",
    "    'Ftrl': Ftrl(learning_rate=best_params['learning_rate'])\n",
    "}\n",
    "\n",
    "optimizer = optimizers[best_params['optimizer']]\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "#n_classes = len(y_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(best_params['neurons'], kernel_size=best_params['kernel'], activation=best_params['activation'], input_shape=(15,9)))\n",
    "\n",
    "if best_params['normalization'] > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "for _ in range(best_params['layers1']):\n",
    "    model.add(Dense(best_params['neurons'], activation=best_params['activation']))\n",
    "\n",
    "if best_params['dropout'] > 0.5:\n",
    "    model.add(Dropout(best_params['dropout_rate'], seed=123))\n",
    "\n",
    "for _ in range(best_params['layers2']):\n",
    "    model.add(Dense(best_params['neurons'], activation=best_params['activation']))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) # sigmoid, tanh, softmax\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10321b45-c8d5-45cd-b30d-d08c5e1fe9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_95\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_95\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_470 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_471 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_472 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_473 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_474 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,380</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_95 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m247\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_470 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_471 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_472 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_473 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m13\u001b[0m)         │           \u001b[38;5;34m182\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_95 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_95 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_474 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m1,380\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,067</span> (27.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,067\u001b[0m (27.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,355</span> (9.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,355\u001b[0m (9.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,712</span> (18.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,712\u001b[0m (18.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58398631-2fda-4201-b7fb-d3907105ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20e43186-0faf-47d8-9fb6-542a37760e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your input data and labels\n",
    "# One-hot encode y_train\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04caa4e9-889b-41ef-a7b7-a36d728c67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17212, 15, 9)\n",
      "y_train_one_hot shape: (17212, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_one_hot shape: {y_train_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4db8ba4-ea15-49c2-a38d-34531c2bd36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "21/21 - 1s - 40ms/step - accuracy: 0.8379 - loss: 0.4395\n",
      "Epoch 2/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8471 - loss: 0.4056\n",
      "Epoch 3/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8529 - loss: 0.3965\n",
      "Epoch 4/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8537 - loss: 0.3917\n",
      "Epoch 5/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8545 - loss: 0.3896\n",
      "Epoch 6/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8545 - loss: 0.3877\n",
      "Epoch 7/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8549 - loss: 0.3869\n",
      "Epoch 8/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8563 - loss: 0.3874\n",
      "Epoch 9/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8568 - loss: 0.3845\n",
      "Epoch 10/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8571 - loss: 0.3830\n",
      "Epoch 11/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8563 - loss: 0.3831\n",
      "Epoch 12/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8573 - loss: 0.3823\n",
      "Epoch 13/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8576 - loss: 0.3814\n",
      "Epoch 14/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8577 - loss: 0.3810\n",
      "Epoch 15/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8589 - loss: 0.3801\n",
      "Epoch 16/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8574 - loss: 0.3798\n",
      "Epoch 17/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8573 - loss: 0.3788\n",
      "Epoch 18/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8578 - loss: 0.3796\n",
      "Epoch 19/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8588 - loss: 0.3776\n",
      "Epoch 20/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8586 - loss: 0.3779\n",
      "Epoch 21/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8592 - loss: 0.3769\n",
      "Epoch 22/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8593 - loss: 0.3769\n",
      "Epoch 23/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8592 - loss: 0.3762\n",
      "Epoch 24/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8597 - loss: 0.3752\n",
      "Epoch 25/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8602 - loss: 0.3747\n",
      "Epoch 26/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8600 - loss: 0.3746\n",
      "Epoch 27/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8597 - loss: 0.3740\n",
      "Epoch 28/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8616 - loss: 0.3734\n",
      "Epoch 29/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8608 - loss: 0.3731\n",
      "Epoch 30/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8613 - loss: 0.3724\n",
      "Epoch 31/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8604 - loss: 0.3725\n",
      "Epoch 32/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8606 - loss: 0.3728\n",
      "Epoch 33/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8613 - loss: 0.3723\n",
      "Epoch 34/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8600 - loss: 0.3714\n",
      "Epoch 35/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8603 - loss: 0.3699\n",
      "Epoch 36/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8611 - loss: 0.3701\n",
      "Epoch 37/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8618 - loss: 0.3694\n",
      "Epoch 38/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8628 - loss: 0.3696\n",
      "Epoch 39/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8618 - loss: 0.3685\n",
      "Epoch 40/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8628 - loss: 0.3684\n",
      "Epoch 41/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8635 - loss: 0.3676\n",
      "Epoch 42/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8640 - loss: 0.3671\n",
      "Epoch 43/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8629 - loss: 0.3674\n",
      "Epoch 44/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8625 - loss: 0.3662\n",
      "Epoch 45/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8632 - loss: 0.3667\n",
      "Epoch 46/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8645 - loss: 0.3659\n",
      "Epoch 47/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8650 - loss: 0.3656\n",
      "Epoch 48/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8645 - loss: 0.3652\n",
      "Epoch 49/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8642 - loss: 0.3651\n",
      "Epoch 50/60\n",
      "21/21 - 0s - 6ms/step - accuracy: 0.8646 - loss: 0.3635\n",
      "Epoch 51/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8645 - loss: 0.3634\n",
      "Epoch 52/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8639 - loss: 0.3634\n",
      "Epoch 53/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8650 - loss: 0.3626\n",
      "Epoch 54/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8652 - loss: 0.3622\n",
      "Epoch 55/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8650 - loss: 0.3635\n",
      "Epoch 56/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8657 - loss: 0.3623\n",
      "Epoch 57/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8652 - loss: 0.3620\n",
      "Epoch 58/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8657 - loss: 0.3614\n",
      "Epoch 59/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8652 - loss: 0.3612\n",
      "Epoch 60/60\n",
      "21/21 - 0s - 5ms/step - accuracy: 0.8660 - loss: 0.3619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x75a3f8cfc470>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_one_hot, batch_size=858, epochs=60, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e733a13-8d86-4ad3-81d4-2168c7b063b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating stations dictionary\n",
    "stations = {\n",
    "    0: 'BASEL',\n",
    "    1: 'BELGRADE',\n",
    "    2: 'BUDAPEST',\n",
    "    3: 'DEBILT',\n",
    "    4: 'DUSSELDORF',\n",
    "    5: 'HEATHROW',\n",
    "    6: 'KASSEL',\n",
    "    7: 'LJUBJANA',\n",
    "    8: 'MAASTRICHT',\n",
    "    9: 'MADRID',\n",
    "    10: 'MUNCHENB',\n",
    "    11: 'OSLO',\n",
    "    12: 'SONNBLICK',\n",
    "    13: 'STOCKHOLM',\n",
    "    14: 'VALENTIA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4442cc02-984c-460b-9823-78350fa7c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, stations):\n",
    "    # Check if y_true and y_pred are one-hot encoded or already class indices\n",
    "    if y_true.ndim == 1:\n",
    "        y_true_labels = y_true\n",
    "    else:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred_labels = y_pred\n",
    "    else:\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    # Map numeric labels to activity names\n",
    "    y_true_series = pd.Series([stations[y] for y in y_true_labels])\n",
    "    y_pred_series = pd.Series([stations[y] for y in y_pred_labels])\n",
    "    \n",
    "    return pd.crosstab(y_true_series, y_pred_series, rownames=['True'], colnames=['Pred'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92e3f36a-7e84-4fb9-bced-962c317290a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before making predictions, convert y_test to one-hot format\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30ffcfd2-6d17-44c6-a48f-ccbb69061e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acd25584-c9f0-4c41-b86f-17bbafefb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.87%\n"
     ]
    }
   ],
   "source": [
    "# Manually calculate accuracy\n",
    "correct_predictions = np.sum(y_test_labels == y_pred_labels)\n",
    "total_samples = len(y_test_labels)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc5ab33e-55bb-446c-94be-dbfdcc0255ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "864053ff-7a62-4114-9f34-5930cc103bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test_one_hot back to class labels\n",
    "y_test_labels = np.argmax(y_test_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e5d5199c-9c04-4f17-81e2-f06934ac1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred        BASEL  BELGRADE  BUDAPEST  DEBILT  DUSSELDORF  HEATHROW  KASSEL  \\\n",
      "True                                                                          \n",
      "BASEL        3505       130        11       4           6        10       0   \n",
      "BELGRADE      233       845        14       2           0         0       0   \n",
      "BUDAPEST       56        62        82       1           2         9       0   \n",
      "DEBILT         29         9         9      28           0         4       0   \n",
      "DUSSELDORF      8         6         4       6           6         1       0   \n",
      "HEATHROW       13        12         7       3           2        44       0   \n",
      "KASSEL          2         7         0       3           0         0       3   \n",
      "LJUBJANA       10         6         3       0           0         3       0   \n",
      "MAASTRICHT      0         0         0       0           1         1       0   \n",
      "MADRID         17        39         9       1           0        11       0   \n",
      "MUNCHENB        6         3         2       0           0         0       0   \n",
      "OSLO            6         0         0       0           0         0       0   \n",
      "STOCKHOLM       2         1         0       0           0         1       0   \n",
      "VALENTIA        2         0         0       0           0         0       0   \n",
      "\n",
      "Pred        LJUBJANA  MAASTRICHT  MADRID  MUNCHENB  OSLO  VALENTIA  \n",
      "True                                                                \n",
      "BASEL              4           1      27         1     0         1  \n",
      "BELGRADE           1           0       5         0     0         0  \n",
      "BUDAPEST           0           0      13         0     0         0  \n",
      "DEBILT             0           0       1         0     0         0  \n",
      "DUSSELDORF         0           1       2         0     0         0  \n",
      "HEATHROW           3           0       6         0     0         0  \n",
      "KASSEL             0           0       0         0     0         0  \n",
      "LJUBJANA          34           1       3         0     0         0  \n",
      "MAASTRICHT         1           1       1         0     0         0  \n",
      "MADRID             5           0     317         0     0         0  \n",
      "MUNCHENB           0           0       2         4     0         0  \n",
      "OSLO               0           0       0         0     1         0  \n",
      "STOCKHOLM          0           0       0         0     0         0  \n",
      "VALENTIA           0           0       0         0     0         0  \n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, stations)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6e2a3-e7ea-44e9-8ebc-e5eb6ff9004c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
